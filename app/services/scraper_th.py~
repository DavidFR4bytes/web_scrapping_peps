from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
import json

def get_page_html(url):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context()
        page = context.new_page()
        page.goto(url, timeout=60000)
        page.wait_for_load_state('networkidle')  # espera que la red esté ociosa
        html = page.content()
        browser.close()
        return html

def extract_peps(html):
    soup = BeautifulSoup(html, 'html.parser')
    peps = []

    # Encontrar el contenedor principal con los nombres (esto varía por página)
    containers = soup.select("div.elementor-widget-container")  # Selector para SOC.go.th

    for div in containers:
        text = div.get_text(separator=" ", strip=True)
        if text:
            # Validación básica: solo guardar nombres largos (omitimos textos vacíos o muy genéricos)
            if len(text) > 5:
                peps.append({
                    "nombre": text
                })

    return peps

def scrape_peps_thailandia_api():
    # URL protegida por Cloudflare
    url = "https://www.soc.go.th/?page_id=182"

    # Paso 1: Obtener HTML desde Playwright
    html = get_page_html(url)

    # Paso 2: Extraer nombres con BeautifulSoup
    pep_data = extract_peps(html)

    # Paso 3: Guardar en un archivo JSON
    with open("peps_tailandia.json", "w", encoding="utf-8") as f:
        json.dump(pep_data, f, ensure_ascii=False, indent=2)

    print(f"Se extrajeron {len(pep_data)} registros y se guardaron en 'peps_tailandia.json'")


