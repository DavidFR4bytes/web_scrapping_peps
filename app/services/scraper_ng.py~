import requests
import os
import csv
import json
import io
import pandas as pd


def scrape_peps_nigeria_api():
    csv_url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vS-0_pci6BoFHpxfPXbDeMD53jvti_TmovR406JK-Z-9lYPCqbUmTk6vZC0hTSRFxHYGTzJJyFRDCxz/pub?output=csv"

    print("Descargando archivo CSV...")

    response = requests.get(csv_url)
    if response.status_code != 200:
        print(f"Error al descargar el archivo: {response.status_code}")
        return

    csv_reader = csv.DictReader(io.StringIO(response.text), delimiter=',')
    pep_data = []

    for row in csv_reader:
        pep = {
            "ID": row["Unique Identifier"],
            "Last Name": row["Last Name"],
            "First Name": row["First Name"],
            "Middle Name": row["Middle Name"],
            "Title": row["Title"],
            "Gender": row["Gender"],
            "Date of Birth": row["Date of Birth"],
            "Present Position": row["Present Position"],
            "Previous Position": row["Previous Position"],
            "PeP Classification": row["PeP Classification"],
            "Official Address": row["Official Address"],
            "State Of Origin": row["State Of Origin"],
        }
        pep_data.append(pep)

    os.makedirs("data", exist_ok=True)
    with open("data/peps_nigeria.json", "w", encoding="utf-8") as f:
        json.dump(pep_data, f, ensure_ascii=False, indent=4)

    print("Scraping de PEPs de Nigeria completado.")


def scrape_peps_nigeria_dot():
    url = "https://peps.directoriolegislativo.org/datasets/nigeria/PEP_data.xlsx"

    try:
        df = pd.read_excel(url)

        # Crear carpeta si no existe
        os.makedirs("data", exist_ok=True)

        # Guardar como JSON
        df.to_json("data/peps_nigeria_dot.json", orient="records", force_ascii=False, indent=4)

        print(f"{len(df)} PEPs de Nigeria (xlsx) guardadas en data/peps_nigeria_xlsx.json")
    except Exception as e:
        print(f"Error al procesar el archivo XLSX: {e}")
