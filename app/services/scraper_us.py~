import requests
from bs4 import BeautifulSoup
import json
import os

def scrape_peps_venezuela_api():
    base_url = "https://www.asambleanacional.gob.ve/diputados?page={}"
    page = 1
    peps = []

    while True:
        print(f"Scrapeando p치gina {page}...")
        url = base_url.format(page)
        response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=30)

        if response.status_code != 200:
            print(f"Error al acceder a la p치gina {page}: {response.status_code}")
            break

        soup = BeautifulSoup(response.content, "html.parser")
        items = soup.select("div.uk-padding-small")

        # Si no hay diputados, hemos llegado al final
        if not items:
            print("No se encontraron m치s diputados en esta p치gina.")
            break

        for item in items:
            nombre_tag = item.select_one("b.an-text-black a")
            partido_tag = item.select_one("small:contains('Partido:')")
            estado_tag = item.select("small")
            imagen_style = item.select_one("div[style*='background-image']")

            nombre = nombre_tag.get_text(strip=True) if nombre_tag else ""
            url_biografia = nombre_tag["href"] if nombre_tag else ""
            partido = partido_tag.get_text(strip=True).replace("Partido:", "").strip() if partido_tag else ""

            estado = ""
            for small in estado_tag:
                if "Estado:" in small.get_text():
                    estado = small.get_text().replace("Estado:", "").strip()

            imagen = ""
            if imagen_style:
                style = imagen_style.get("style", "")
                if "background-image" in style:
                    start = style.find("url(")
                    end = style.find(")", start)
                    imagen = style[start + 4:end]

            peps.append({
                "nombre": nombre,
                "partido": partido,
                "estado": estado,
                "imagen": imagen,
                "url_biografia": url_biografia
            })

        page += 1

    # Guardar en JSON
    os.makedirs("data", exist_ok=True)
    with open("data/peps_venezuela.json", "w", encoding="utf-8") as f:
        json.dump(peps, f, ensure_ascii=False, indent=4)

    print(f"Se extrajeron {len(peps)} diputados de Venezuela.")

# Ejecutar el script
if __name__ == "__main__":
    scrape_peps_venezuela_api()
