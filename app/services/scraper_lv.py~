import requests
from bs4 import BeautifulSoup
import json
import re
import os

def scrape_peps_latvia_api():
    url = "https://titania.saeima.lv/personal/deputati/saeima14_depweb_public.nsf/deputies?OpenView&lang=EN&count=1000"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }

    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, "html.parser")

    # Extraer el contenido del div con los drawDep({...})
    script_data = soup.find("div", {"id": "viewHolderText"})
    if not script_data:
        print("No se encontró el div con los datos.")
        return

    text = script_data.get_text()

    # Buscar todas las llamadas drawDep({ ... })
    pattern = r"drawDep\(\{.*?\}\);"
    matches = re.findall(pattern, text, re.DOTALL)

    peps = []
    for match in matches:
        json_like = match.replace("drawDep(", "").replace(");", "")
        pep_data = json.loads(json_like)
        peps.append({
            "name": pep_data.get("name", ""),
            "surname": pep_data.get("sname", ""),
            "parliamentary_group": pep_data.get("lst", ""),
            "profile_url": f"https://titania.saeima.lv/personal/deputati/saeima14_depweb_public.nsf/depArchive.html?ReadForm&unid={pep_data.get('unid')}&url=./0/{pep_data.get('unid')}?OpenDocument&lang=EN"
        })

    # Guardar en archivo JSON
    os.makedirs("data", exist_ok=True)
    with open("data/peps_latvia.json", "w", encoding="utf-8") as f:
        json.dump(peps, f, ensure_ascii=False, indent=4)

    print(f"{len(peps)} PEPs extraídas y guardadas en data/peps_latvia.json")
